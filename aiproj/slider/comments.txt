For our solution, our agent's init() method uses our modified Board class, storing an internal representation of it, while noting the which player it is. The update() method then updates the cells of the board with the opponent's and our move, after calling our move method for the latter, using our modified Cell, Horizontal and Vertical classes, with the latter two implementing our Piece interface from Part A of the project, to fit the Referee class and SliderPlayer interface. The move() function uses all the above classes which is in the aiproj.slider package.

For our code, we would like to acknowledge the use of Chua's (2012) Java Graphics Tutorial (https://www3.ntu.edu.sg/home/ehchua/programming/java/javagame_tictactoe_ai.html) and the Wikipedia article for Alpha-Beta Pruning (https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) code as reference for our solution.

The approach taken by our agent in determining the best moves to make included searching through the use of the minimax algorithm. However, as the minimax algorithm took a long time, due to its depth, we had included alpha-beta pruning so as to prune the branches that we did not require, thus improving our CPU Time by around 3 times, at a depth of four. For our evaluation function, we had placed more emphasis on moving our piece forward, but will attempt to block the closest adjacent enemy pieces on its way. By these heuristics, our pieces will not move off the board until the score for moving off is more than the score for blocking. We had also attempted to use Manhattan Distance to determine a score for moving all pieces off the board.